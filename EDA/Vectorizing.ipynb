{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Read in data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  label                                            message\n0   ham  I've been searching for the right words to tha...\n1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n2   ham  Nah I don't think he goes to usf, he lives aro...\n3   ham  Even my brother is not like to speak with me. ...\n4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>I've been searching for the right words to tha...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>Even my brother is not like to speak with me. ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('../Data/SMSSpamCollection.tsv', sep='\\t', names=['label', 'message'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Function for cleaning data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [word for word in tokens if word not in stopwords]\n",
    "    return text\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Apply CountVectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5568, 11519)\n",
      "['' '0' '008704050406' ... 'ü' 'üll' '〨ud']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(analyzer=clean_text)\n",
    "X_counts = count_vect.fit_transform(dataset['message'])\n",
    "print(X_counts.shape)\n",
    "print(count_vect.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' '0' '008704050406' ... 'ü' 'üll' '〨ud']\n"
     ]
    }
   ],
   "source": [
    "print(count_vect.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Apply CountVectorizer on a sample of data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 233)\n",
      "['08002986030' '08452810075over18s' '09061701461' '1' '100' '100000' '11'\n",
      " '12' '150pday' '16' '2' '20000' '2005' '21st' '3' '4' '4403LDNW1A7RW18'\n",
      " '4txtú120' '6days' '81010' '87077' '87121' '87575' '9' '900' 'A' 'Aft'\n",
      " 'Ard' 'As' 'CASH' 'CLAIM' 'CSH11' 'Call' 'Callers' 'Callertune' 'Claim'\n",
      " 'Co' 'Cost' 'Cup' 'DATE' 'ENGLAND' 'Eh' 'England' 'Even' 'FA' 'FREE'\n",
      " 'Fine' 'Free' 'From' 'HAVE' 'HL' 'Had' 'He' 'I' 'Im' 'Is' 'Ive' 'Jackpot'\n",
      " 'KL341' 'LCCLTD' 'Macedonia' 'May' 'Melle' 'Minnaminunginte' 'Mobile'\n",
      " 'Nah' 'No' 'Nurungu' 'ON' 'Oh' 'Oru' 'POBOX' 'POBOXox36504W45WQ' 'Press'\n",
      " 'Prize' 'R' 'Reply' 'SCOTLAND' 'SIX' 'SUNDAY' 'So' 'TC' 'Text' 'That'\n",
      " 'The' 'Then' 'They' 'To' 'TryWALES' 'TsandCs' 'Txt' 'U' 'URGENT' 'Update'\n",
      " 'Valid' 'Vettam' 'WAP' 'WILL' 'WINNER' 'WITH' 'XXXMobileMovieClub' 'Yes'\n",
      " 'You' 'aids' 'already' 'anymore' 'apply' 'around' 'b' 'blessing'\n",
      " 'breather' 'brother' 'call' 'callertune' 'camera' 'chances' 'claim'\n",
      " 'click' 'code' 'colour' 'comin' 'comp' 'copy' 'credit' 'cried' 'customer'\n",
      " 'da' 'dont' 'eg' 'enough' 'entitled' 'entry' 'feel' 'final' 'finish'\n",
      " 'first' 'friends' 'fulfil' 'go' 'goalsteam' 'goes' 'going' 'gonna' 'gota'\n",
      " 'granted' 'ha' 'help' 'home' 'hours' 'httpwap' 'info' 'joking' 'k' 'kim'\n",
      " 'lar' 'latest' 'like' 'link' 'lives' 'lor' 'lunch' 'make' 'membership'\n",
      " 'message' 'miss' 'mobile' 'mobiles' 'months' 'name' 'national' 'naughty'\n",
      " 'network' 'news' 'next' 'patent' 'pay' 'per' 'pounds' 'prize' 'promise'\n",
      " 'questionstd' 'rateTCs' 'receive' 'receivea' 'remember' 'request'\n",
      " 'reward' 'right' 'searching' 'selected' 'send' 'seriously' 'set' 'smth'\n",
      " 'soon' 'speak' 'spell' 'stock' 'str' 'stuff' 'take' 'talk' 'team' 'thank'\n",
      " 'think' 'though' 'times' 'tkts' 'today' 'tonight' 'treat' 'try' 'txt' 'u'\n",
      " 'ur' 'use' 'usf' 'v' 'valued' 'want' 'watching' 'way' 'week' 'wet' 'win'\n",
      " 'wkly' 'wonderful' 'wont' 'word' 'words' 'wwwdbuknet'\n",
      " 'xxxmobilemovieclubcomnQJKGIGHJJGCBL' 'ü']\n"
     ]
    }
   ],
   "source": [
    "data_sample = dataset[0:20]\n",
    "\n",
    "count_vect_sample = CountVectorizer(analyzer=clean_text)\n",
    "X_counts_sample = count_vect_sample.fit_transform(data_sample['message'])\n",
    "print(X_counts_sample.shape)\n",
    "print(count_vect_sample.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}